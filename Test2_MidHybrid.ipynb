{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading dataset...\n",
      "Preparing datasets...\n",
      "Class Distribution in Train Dataset: {np.int64(0): np.int64(834), np.int64(1): np.int64(806)}\n",
      "Final Train set size: 1640, Test set size: 410\n",
      "Initializing Hybrid SVM (Quantum Kernel)...\n",
      "Applying PCA...\n",
      "PCA Variance Ratio: 1.0000\n",
      "Initializing quantum kernel...\n",
      "Training Hybrid SVM...\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 4 folds for each of 240 candidates, totalling 960 fits\n",
      "Best Parameters: {'C': 10, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Cross-Validation Score: 0.9848\n",
      "Hybrid SVM training complete. Time taken: 5.25 minutes.\n",
      "Memory Usage: 22.71 MB (during training)\n",
      "Evaluating Hybrid SVM...\n",
      "Hybrid SVM evaluation complete. Time taken: 0.00 minutes.\n",
      "Memory Usage: 4.63 MB (during evaluation)\n",
      "Hybrid SVM Accuracy: 0.9878\n",
      "Precision: 0.9881\n",
      "Recall: 0.9878\n",
      "F1 Score: 0.9878\n",
      "Confusion Matrix:\n",
      " [[209   0]\n",
      " [  5 196]]\n",
      "Saving Hybrid SVM model...\n",
      "Hybrid SVM model saved to hybrid_svm_midmodel.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import psutil  # For memory tracking\n",
    "import pandas as pd\n",
    "import joblib  # For model saving/loading\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC  # Classical SVM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "class HybridSVM:\n",
    "    def __init__(self, data, pca_components, reps=1):\n",
    "        print(\"Initializing Hybrid SVM (Quantum Kernel)...\")\n",
    "        self.data = data\n",
    "        self.pca_components = pca_components\n",
    "        self.reps = reps\n",
    "        self.apply_pca()\n",
    "        self.initialize_quantum_kernel()\n",
    "\n",
    "    def apply_pca(self):\n",
    "        \"\"\"Reduce feature dimensions using PCA\"\"\"\n",
    "        print(\"Applying PCA...\")\n",
    "        pca = PCA(n_components=self.pca_components)\n",
    "        self.data.train_features = pca.fit_transform(self.data.train_features)\n",
    "        self.data.test_features = pca.transform(self.data.test_features)\n",
    "        print(f\"PCA Variance Ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "    def initialize_quantum_kernel(self):\n",
    "        \"\"\"Set up the quantum feature map and fidelity kernel\"\"\"\n",
    "        print(\"Initializing quantum kernel...\")\n",
    "        feature_map = ZZFeatureMap(feature_dimension=self.pca_components, reps=self.reps, entanglement=\"linear\")\n",
    "        self.quantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "\n",
    "    @staticmethod\n",
    "    def svm_hyperparameter_tuning(train_features, train_labels):\n",
    "        print(\"Starting hyperparameter tuning...\")\n",
    "\n",
    "        param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "        'degree': [2, 3, 4]  # Only relevant for 'poly'\n",
    "        }\n",
    "\n",
    "        svc = SVC()\n",
    "        grid_search = GridSearchCV(svc, param_grid, cv=4, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "        grid_search.fit(train_features, train_labels)\n",
    "\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        return grid_search.best_estimator_\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Train Hybrid SVM with memory tracking\"\"\"\n",
    "        print(\"Training Hybrid SVM...\")\n",
    "\n",
    "        # Transform dataset using the quantum kernel\n",
    "        quantum_train_features = self.quantum_kernel.evaluate(self.data.train_features, self.data.train_features)\n",
    "\n",
    "        # Track memory usage before training\n",
    "        process = psutil.Process()\n",
    "        mem_before = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.svm = self.svm_hyperparameter_tuning(quantum_train_features, self.data.train_labels)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Track memory usage after training\n",
    "        mem_after = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "        print(f\"Hybrid SVM training complete. Time taken: {(end_time - start_time) / 60:.2f} minutes.\")\n",
    "        print(f\"Memory Usage: {mem_after - mem_before:.2f} MB (during training)\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate Hybrid SVM using accuracy metrics and memory tracking\"\"\"\n",
    "        print(\"Evaluating Hybrid SVM...\")\n",
    "\n",
    "        # Transform test set using the quantum kernel\n",
    "        quantum_test_features = self.quantum_kernel.evaluate(self.data.test_features, self.data.train_features)\n",
    "\n",
    "        # Track memory usage before evaluation\n",
    "        process = psutil.Process()\n",
    "        mem_before = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "        start_time = time.time()\n",
    "        predictions = self.svm.predict(quantum_test_features)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Track memory usage after evaluation\n",
    "        mem_after = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "        print(f\"Hybrid SVM evaluation complete. Time taken: {(end_time - start_time) / 60:.2f} minutes.\")\n",
    "        print(f\"Memory Usage: {mem_after - mem_before:.2f} MB (during evaluation)\")\n",
    "\n",
    "        # Compute performance metrics\n",
    "        acc = accuracy_score(self.data.test_labels, predictions)\n",
    "        prec = precision_score(self.data.test_labels, predictions, average=\"weighted\")\n",
    "        rec = recall_score(self.data.test_labels, predictions, average=\"weighted\")\n",
    "        f1 = f1_score(self.data.test_labels, predictions, average=\"weighted\")\n",
    "        conf_matrix = confusion_matrix(self.data.test_labels, predictions)\n",
    "\n",
    "        # Display results\n",
    "        print(f\"Hybrid SVM Accuracy: {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall: {rec:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1_score\": f1,\n",
    "            \"confusion_matrix\": conf_matrix\n",
    "        }\n",
    "    \n",
    "    def save_model(self, filename=\"hybrid_svm_mid\"\n",
    "    \"model.pkl\"):\n",
    "        \"\"\"Save the trained Hybrid SVM model\"\"\"\n",
    "        if not hasattr(self, \"svm\") or self.svm is None:\n",
    "            print(\"Error: No trained model found. Train the Hybrid SVM first.\")\n",
    "            return\n",
    "\n",
    "        print(\"Saving Hybrid SVM model...\")\n",
    "        joblib.dump(self.svm, filename)\n",
    "        print(f\"Hybrid SVM model saved to {filename}\")\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, filename):\n",
    "        print(\"Initializing dataset...\")\n",
    "        self.filename = filename\n",
    "        self.load_data()\n",
    "        self.prepare_datasets()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load dataset and apply necessary preprocessing\"\"\"\n",
    "        print(\"Loading dataset...\")\n",
    "        self.df = pd.read_csv(self.filename)\n",
    "\n",
    "    def prepare_datasets(self):\n",
    "        \"\"\"Split dataset into train/test and scale features\"\"\"\n",
    "        print(\"Preparing datasets...\")\n",
    "\n",
    "        # Extract features and labels\n",
    "        features = self.df.drop(columns=[\"HAS ADHD\"]).to_numpy()\n",
    "        labels = self.df[\"HAS ADHD\"].to_numpy()\n",
    "\n",
    "        # Scale features to the range (0, 2Ï€)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 2 * np.pi))\n",
    "        features = scaler.fit_transform(features)\n",
    "\n",
    "        # Stratified train-test split\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "            features, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "        )\n",
    "\n",
    "        # Class distribution in train dataset\n",
    "        unique, counts = np.unique(train_labels, return_counts=True)\n",
    "        class_distribution = dict(zip(unique, counts))\n",
    "        print(f\"Class Distribution in Train Dataset: {class_distribution}\")\n",
    "\n",
    "        # Store processed features and labels\n",
    "        self.train_features, self.train_labels = train_features, train_labels\n",
    "        self.test_features, self.test_labels = test_features, test_labels\n",
    "\n",
    "        print(f\"Final Train set size: {len(self.train_features)}, Test set size: {len(self.test_features)}\")\n",
    "\n",
    "# Load dataset and train Hybrid SVM\n",
    "dataset = Data('MLsheet - SRSno-avg.csv')\n",
    "hybrid_svm = HybridSVM(dataset, pca_components=6, reps=2)\n",
    "hybrid_svm.fit()\n",
    "\n",
    "# Evaluate Hybrid SVM performance\n",
    "metrics = hybrid_svm.evaluate()\n",
    "\n",
    "# Save the trained model for later use\n",
    "hybrid_svm.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
